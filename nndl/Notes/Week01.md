# What is a Neural Network?

Try to predict price of a house based on size, first pass would be linear regression (simplest NN). ReLU -- REctified Linear Unit, function that is zero some times,and a straight line others. Start to look at a more complex model -- # bathrooms, size, zip/postal code, wealth. This leads to some inferred parameters (size of family, walkability, school quality), and this leads to a predicted price.

Start stacking neurons (functions to take input and provide modeled/predicted output) to build larger and more complex networks.

# Supervised Learning with Neural Networks

Biggest application of NNs so far is with supervised learning, where you have some inputs and labeled outputs to train. Different types of NN architectures (NN, CNN, RNN, hybrid). Structured data (well defined inputs) versus unstructured (audio, images, text). Historically, easier to work with structured data. Techniques around for a long time, but just now starting to gain widespread use and adoption.

# Why is Deep Learning Taking Off?

Biggest driver of DL adoption is combination of larger and larger amounts of data and also larger and larger amounts of compute (cloud, GPGPUs). DL gets better with more data, but you need to scale both sides (data and compute) in order to do practically.

Increasingly seeing innovation in the algorithmic space, switch from sigmoid to ReLU functions as one example. Sigmoid at tails slows down learning because gradients gradually going to zero.

Very iterative development process, need quick feedback. Train, test, modify cycle.

# About This Course

Part of 5 course cycle. At the end of each week, 10 questions (plus programming exercises).

Week 1 -- Introduction
Week 2 -- Basics of NN programming, forward and back prop
Week 3 -- 1-layer hidden NN
Week 4 -- Deep NN

# FAQs

# Resources

Discussion forums @ Coursera course website.

# Discussion Forums
